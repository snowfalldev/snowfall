// currently outputs almost every possible error in the lexer, intended for testing

pub const test = "haiii 👋";

//! garbage-level doc comment

// this is a regular comment, doesn't get tokenized
/// this is a doc comment, gets tokenized and attached to the function below
pub func testFunc(str: string, num: number) void {
  str[0] = '\x62';
  var a = +43;
  a += b-2;
  std.printf("%s %d\n", str, a);
  std.print("à́̀́̀́̀́̀́̀́̀́̀");
}

/*
bigger comment
look it's multiline waow
*/
/**
bigger doc comment
im multiline too!!
*/
pub func main() void {
  const really_stupidly_long_identifier_that_doesnt_need_to_exist_just_stop = "lol";
  testFunc(test, -1);
  const um = '\n';
  const um2 = 'na';
  const um3 = '\xPF';
  const um4 = '\x_F';
  const um5 = '\u{DAAA}';
  const yeah = '\xFF';
  std.println("Hello, world!");
  std.print('\u{1F480 }');
  std.print('\u{1F48 0}');
  std.print('\u{1F480}');
  std.print('\u{FFFFFFFFF}');
  std.print('\u{FFFFFF}');
  std.print(" <- skull\n\u{1F480}\u{1_F480}💀 <- oh it's here thrice\n");
  std.println(`1 + 2 = {1 + 2}`);
  std.println("0.1 * 5.5 = ", 0.55);
  std.println(`3 + 1 = {4}`);
  std.println("0.2 * 3.3 = ", 6.6e-1);
  std.println(`squiggly brackets: \{}`);
  @panic("welp");
  const epic_fail = '';
  const epic_fail_2 = '
}
